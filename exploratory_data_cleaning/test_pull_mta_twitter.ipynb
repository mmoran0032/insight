{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test Twitter Pull\n",
    "==========\n",
    "\n",
    "We need the MTA's (`@NYCTSubway`) tweets to see where we're getting delays, and when they resolve."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import json\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import tweepy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('credentials.json', 'r') as f:\n",
    "    creds = json.load(f)\n",
    "\n",
    "auth = tweepy.OAuthHandler(creds['consumer_key'],\n",
    "                           creds['consumer_secret'])\n",
    "auth.set_access_token(creds['access_token_key'],\n",
    "                      creds['access_token_secret'])\n",
    "api = tweepy.API(auth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('#ServiceAlert: Main St bound 7 trains running with delays, due to signal problems at Hunters Point. Allow additional travel time.',\n",
       " 870061323232702464,\n",
       " datetime.datetime(2017, 5, 31, 23, 35, 59))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mta_tweets = api.user_timeline(screen_name='NYCTSubway', count=200)\n",
    "mta_tweets[0].text, mta_tweets[0].id, mta_tweets[0].created_at"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Wed May 31 23:35:59 +0000 2017'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = mta_tweets[0]\n",
    "test._json['created_at']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.datetime(2017, 5, 31, 23, 35, 59, tzinfo=datetime.timezone.utc)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "datestr = test._json['created_at']\n",
    "dt = datetime.strptime(datestr, '%a %b %d %H:%M:%S %z %Y')\n",
    "dt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pull a bunch of tweets\n",
    "---------------------------\n",
    "\n",
    "Adapted from https://gist.github.com/yanofsky/5436496"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting tweets before 869898260248494079\n",
      "getting tweets before 869571143837126656\n",
      "getting tweets before 869090461587210239\n",
      "getting tweets before 868600831574237184\n",
      "getting tweets before 868226378218582015\n",
      "getting tweets before 867952590180409344\n",
      "getting tweets before 867732443608035327\n",
      "getting tweets before 867462984335073280\n",
      "getting tweets before 867182900269248511\n",
      "getting tweets before 866809474912268289\n",
      "getting tweets before 866569185593315328\n",
      "getting tweets before 865958061311238145\n",
      "getting tweets before 865675763944570880\n",
      "getting tweets before 865413297780137983\n",
      "getting tweets before 865290134375325696\n",
      "getting tweets before 864959304423657471\n",
      "getting tweets before 864947194452901887\n",
      "getting tweets before 864936284380430335\n"
     ]
    }
   ],
   "source": [
    "#make initial request for most recent tweets (200 is the maximum allowed count)\n",
    "new_tweets = api.user_timeline(screen_name='NYCTSubway', count=200)\n",
    "tweets = new_tweets.copy()\n",
    "oldest = tweets[-1].id - 1\n",
    "\n",
    "while len(new_tweets) > 0:\n",
    "    print(f'getting tweets before {oldest}')\n",
    "\n",
    "    #all subsiquent requests use the max_id param to prevent duplicates\n",
    "    new_tweets = api.user_timeline(screen_name='NYCTSubway', count=200, max_id=oldest)\n",
    "    tweets.extend(new_tweets)\n",
    "    oldest = tweets[-1].id - 1\n",
    "\n",
    "#transform the tweepy tweets into a 2D array that will populate the csv\n",
    "outtweets = [[t.id_str, t.created_at, t.text] for t in tweets\n",
    "             if t.text.startswith('#ServiceAlert')]\n",
    "\n",
    "import csv\n",
    "\n",
    "#write the csv\n",
    "with open('MTA_tweets.csv', 'w') as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow(['id', 'created_at', 'text'])\n",
    "    writer.writerows(outtweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   898  18467 144419 MTA_tweets.csv\r\n"
     ]
    }
   ],
   "source": [
    "!wc MTA_tweets.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['870068006403100672',\n",
       "  datetime.datetime(2017, 6, 1, 0, 2, 32),\n",
       "  '#ServiceAlert: n/b, 2 &amp; 5 trains are running with delays due to signal problems at Freeman St. Allow additional travel time.'],\n",
       " ['864936284380430336',\n",
       "  datetime.datetime(2017, 5, 17, 20, 10, 54),\n",
       "  '#ServiceAlert:s/b A and D trains are running local 125 St to 59 St, due to a sick passenger at 125 St. Allow additional travel time.'])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outtweets[0], outtweets[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pull Trains from Tweet\n",
    "-------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2', '5']"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def filter_trains(text):\n",
    "    replacements = ['&AMP;', '.', ',', ':']\n",
    "    new_text = text.upper()\n",
    "    for r in replacements:\n",
    "        new_text = new_text.replace(r, '')\n",
    "    \n",
    "    # pull single characters\n",
    "    new_text = new_text.split()\n",
    "    trains = list(filter(lambda x: len(x) == 1, new_text))\n",
    "    return trains\n",
    "\n",
    "filter_trains(outtweets[0][2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Determine most delay tweets\n",
    "---------------------------------\n",
    "\n",
    "To guide this MVP, we can see which lines had the most delay notices, and work on just those lines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('A', 253),\n",
       " ('F', 210),\n",
       " ('4', 153),\n",
       " ('E', 141),\n",
       " ('R', 107),\n",
       " ('W', 102),\n",
       " ('2', 97),\n",
       " ('5', 94),\n",
       " ('N', 91),\n",
       " ('6', 79)]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "trains = [filter_trains(t[2]) for t in outtweets]\n",
    "flatten = lambda l: [item for sublist in l for item in sublist]\n",
    "trains_flat = flatten(trains)\n",
    "\n",
    "train_freq = Counter(trains_flat)\n",
    "train_freq.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
