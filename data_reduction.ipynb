{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Station elasticity\n",
    "===========\n",
    "\n",
    "We need to find station-pair elasticity and store it as a large dataframe or matrix. Every time we get a new shock event, we can include those results in our table as well, which is great! Right now, the only shock event I have looked at is the opening of the Q, and for there I'll assume that all of the stations share the resulting elasticity with the other stations, since there is no way to separate them out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import pymc3 as pm\n",
    "\n",
    "from sqlalchemy import create_engine\n",
    "from sqlalchemy_utils import database_exists, create_database\n",
    "import psycopg2\n",
    "\n",
    "user = 'mikemoran'\n",
    "database = 'stations'\n",
    "\n",
    "engine = create_engine(f'postgres://{user}@localhost/{database}')\n",
    "conn = psycopg2.connect(database=database, user=user)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>station</th>\n",
       "      <th>linename</th>\n",
       "      <th>c_a</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unit</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>R001</th>\n",
       "      <td>SOUTH FERRY</td>\n",
       "      <td>1R</td>\n",
       "      <td>R101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R001</th>\n",
       "      <td>SOUTH FERRY</td>\n",
       "      <td>1RW</td>\n",
       "      <td>R101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R001</th>\n",
       "      <td>WHITEHALL S-FRY</td>\n",
       "      <td>R1</td>\n",
       "      <td>A058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R001</th>\n",
       "      <td>WHITEHALL S-FRY</td>\n",
       "      <td>R1</td>\n",
       "      <td>A060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R001</th>\n",
       "      <td>WHITEHALL S-FRY</td>\n",
       "      <td>R1W</td>\n",
       "      <td>A058</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              station linename   c_a\n",
       "unit                                \n",
       "R001      SOUTH FERRY       1R  R101\n",
       "R001      SOUTH FERRY      1RW  R101\n",
       "R001  WHITEHALL S-FRY       R1  A058\n",
       "R001  WHITEHALL S-FRY       R1  A060\n",
       "R001  WHITEHALL S-FRY      R1W  A058"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = '''\n",
    "    select unit, c_a from station_info\n",
    "        order by unit asc;\n",
    "'''\n",
    "\n",
    "query_2 = '''\n",
    "    select * from station_info;\n",
    "'''\n",
    "\n",
    "station_details = pd.read_sql(query_2, conn)\n",
    "station_details.drop_duplicates(inplace=True)\n",
    "station_details.drop('index', axis=1, inplace=True)\n",
    "station_details.set_index('unit', inplace=True)\n",
    "# station_details[station_details.station.str.contains('FULTON')]\n",
    "station_details.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['R101', 'R101', 'A058', 'A060', 'A058', 'A060', 'A058', 'A060'], dtype=object)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "station_details.loc['R001'].c_a.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def read_ca(table, conn):\n",
    "    query = '''\n",
    "        select date_time, scp,\n",
    "                sum(abs(dentries)) entries,\n",
    "                sum(abs(dexits)) exits\n",
    "            from \"{}\"\n",
    "            group by date_time, scp;\n",
    "    '''\n",
    "    df = (pd.read_sql(query.format(table), conn)\n",
    "            .set_index('date_time', drop=True)\n",
    "            .sort_index())\n",
    "    df[['entries', 'exits']] = np.abs(df[['entries', 'exits']])\n",
    "    df[(df.entries > 100000) | (df.exits > 100000)] = np.NaN\n",
    "    df_summed = df.groupby('date_time')[['entries', 'exits']].sum()\n",
    "    df_regularized = df_summed.resample('4H').apply(sum)\n",
    "    return df_regularized\n",
    "\n",
    "test = read_ca('R101', conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     entries   exits\n",
      "date_time                           \n",
      "2012-05-26 00:00:00      NaN     NaN\n",
      "2012-05-26 04:00:00    175.0   381.0\n",
      "2012-05-26 08:00:00    730.0  1252.0\n",
      "2012-05-26 12:00:00   2639.0  6306.0\n",
      "2012-05-26 16:00:00   5338.0  4458.0\n",
      "                     entries  exits\n",
      "date_time                          \n",
      "2010-04-17 00:00:00      NaN    NaN\n",
      "2010-04-17 04:00:00      1.0    0.0\n",
      "2010-04-17 08:00:00      0.0    0.0\n",
      "2010-04-17 12:00:00      0.0    0.0\n",
      "2010-04-17 16:00:00      0.0    0.0\n",
      "                     entries  exits\n",
      "date_time                          \n",
      "2010-04-17 00:00:00      NaN    NaN\n",
      "2010-04-17 04:00:00      0.0    8.0\n",
      "2010-04-17 08:00:00      1.0    5.0\n",
      "2010-04-17 12:00:00      1.0    9.0\n",
      "2010-04-17 16:00:00      1.0    5.0\n"
     ]
    }
   ],
   "source": [
    "r101 = read_ca('R101', conn)\n",
    "a058 = read_ca('A058', conn)\n",
    "a060 = read_ca('A060', conn)\n",
    "\n",
    "print(r101.head(), a058.head(), a060.head(), sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test = (r101.join(a058, rsuffix='1', how='outer')\n",
    "            .join(a060, rsuffix='2', how='outer'))\n",
    "test['enter'] = test[['entries', 'entries1', 'entries2']].sum(axis=1)\n",
    "test['exit'] = test[['exits', 'exits1', 'exits2']].sum(axis=1)\n",
    "test_i = test.drop(['entries', 'entries1', 'entries2', 'exits', 'exits1', 'exits2'], axis=1)\n",
    "# test_i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def combine_frames(frames):\n",
    "    frame0 = frames.pop(0)\n",
    "    for i, df in enumerate(frames):\n",
    "        frame0 = frame0.join(df, rsuffix=str(i), how='outer')\n",
    "    entry_cols = list(filter(lambda x: x.startswith('entries'), frame0.columns))\n",
    "    exit_cols = list(filter(lambda x: x.startswith('exits'), frame0.columns))\n",
    "    frame0['enter'] = frame0[entry_cols].sum(axis=1)\n",
    "    frame0['exit'] = frame0[exit_cols].sum(axis=1)\n",
    "    return frame0.drop([*entry_cols, *exit_cols], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "units = station_details.index.unique()\n",
    "unit_ca_groups = {u: station_details.loc[u].values.reshape(1, -1)[0].tolist() for u in units}\n",
    "# unit_ca_groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>station</th>\n",
       "      <th>linename</th>\n",
       "      <th>c_a</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unit</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>R014</th>\n",
       "      <td>FULTON ST</td>\n",
       "      <td>2345ACJZ</td>\n",
       "      <td>N095A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R014</th>\n",
       "      <td>FULTON ST</td>\n",
       "      <td>2345ACJZ</td>\n",
       "      <td>R205A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R014</th>\n",
       "      <td>FULTON ST</td>\n",
       "      <td>2345ACJZ</td>\n",
       "      <td>R206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R014</th>\n",
       "      <td>FULTON ST</td>\n",
       "      <td>2345ACJZ</td>\n",
       "      <td>R208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R014</th>\n",
       "      <td>FULTON ST</td>\n",
       "      <td>ACJZ2345</td>\n",
       "      <td>N095</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        station  linename    c_a\n",
       "unit                            \n",
       "R014  FULTON ST  2345ACJZ  N095A\n",
       "R014  FULTON ST  2345ACJZ  R205A\n",
       "R014  FULTON ST  2345ACJZ   R206\n",
       "R014  FULTON ST  2345ACJZ   R208\n",
       "R014  FULTON ST  ACJZ2345   N095"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "station_details.loc['R014']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "new_database = 'fullstations'\n",
    "\n",
    "new_engine = create_engine(f'postgres://{user}@localhost/{new_database}')\n",
    "if not database_exists(new_engine.url):\n",
    "    create_database(new_engine.url)\n",
    "new_conn = psycopg2.connect(database=new_database, user=user)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "station_details.to_sql('details', new_engine, if_exists='replace')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 R001 2017-06-14 19:09:29.472091\n",
      "25 R028 2017-06-14 19:11:08.243777\n",
      "50 R053 2017-06-14 19:12:35.866470\n",
      "75 R085 2017-06-14 19:13:47.089950\n",
      "100 R110 2017-06-14 19:14:54.758638\n",
      "125 R135 2017-06-14 19:16:05.768106\n",
      "150 R160 2017-06-14 19:17:19.188406\n",
      "175 R185 2017-06-14 19:18:32.969629\n",
      "200 R210 2017-06-14 19:19:37.888539\n",
      "225 R235 2017-06-14 19:20:42.506983\n",
      "250 R260 2017-06-14 19:21:44.824226\n",
      "275 R285 2017-06-14 19:22:45.815734\n",
      "300 R311 2017-06-14 19:23:46.978725\n",
      "325 R336 2017-06-14 19:24:48.762043\n",
      "350 R362 2017-06-14 19:25:49.454647\n",
      "375 R387 2017-06-14 19:26:45.085563\n",
      "400 R413 2017-06-14 19:27:41.006522\n",
      "425 R438 2017-06-14 19:28:35.272685\n",
      "450 R468 2017-06-14 19:29:36.338636\n",
      "Done: 2017-06-14 19:30:32.705504\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "for i, (unit, ca_list) in enumerate(unit_ca_groups.items()):\n",
    "    if i % 25 == 0:\n",
    "        print(i, unit, datetime.now())\n",
    "    frames = [read_ca(ca, conn) for ca in ca_list]\n",
    "    df = combine_frames(frames)\n",
    "    new_name = unit.lower()\n",
    "    df.to_sql(new_name, new_engine, if_exists='replace')\n",
    "else:\n",
    "    print('Done:', datetime.now())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
